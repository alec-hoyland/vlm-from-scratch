# VLM from Scratch

This repo contains the source code for a Llava-like VLM written from scratch as well as a script to train the model. 

All the model code is in `/vlm`.

The recommended training dataset is [tiny-shakespeare](https://huggingface.co/datasets/karpathy/tiny_shakespeare).
